{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e72a842",
   "metadata": {},
   "source": [
    "# Prepares data to go into SHETRAN and HIPIMS\n",
    "\n",
    "## Notes\n",
    "- This code relies on the following code\n",
    "    1. `read_met` - reads in 5-minute gridded (composite and processed C-band weather radar from the Met Office ftp server.\n",
    "    2. `read_ea` - reads in 15-minute rain gauge data from the EA website API.\n",
    "    3. `read_cs` - reads in varying resolution rain gauge data from NGIF and UO APIand accumulates up to 15-minute resolution data.\n",
    "    4. `read_cs_radar` - reads in Urban Observatory X-band radar code, processes it and accumulates it up to 15 minutes.\n",
    "    5. `intense_qc` - quality controls all gauge data using intense-qc code (Note: this is designed for hourly rain gauge data). \n",
    "- It also requires the bounding box shapefile for HIPIMS and the Tyne mask file for SHETRAN (these are in the `static.zip` sent on teams).\n",
    "\n",
    "## What does this code do?\n",
    "\n",
    "### Reads in data\n",
    "1. Read in radar data (if exists)\n",
    "    - Met Office radar data\n",
    "    - Urban Observatory radar data\n",
    "2. Read in quality controlled rain gauge data (if exists)\n",
    "    - Environment Agency rain gauges\n",
    "    - Urban Observatory rain gauges\n",
    "    - Citizen Science rain gauges\n",
    "    - National Green Infrastructure Facility rain gauges\n",
    "3. Identifies best data to use\n",
    "    - Uses data priority for HIPIMS\n",
    "    - Uses data priority for SHETRAN\n",
    "4. Grids/merges data\n",
    "    - Combines different data types to provide gridded 15-minute rainfall estimates (1km resolution)\n",
    "4. Saves data in correct format for models\n",
    "    - Clips and saves data in correct format for HIPIMS\n",
    "    - Clips and saves data in correct format for SHETRAN\n",
    "    \n",
    "### Prioritises data for input into HIPIMS model\n",
    "1. High resolution (250m) X-band radar data, merged with rain gauges, which is conditional on Met Office C-band radar data.\n",
    "2. High resolution (250m) X-band radar data, conditional on Met Office C-band radar data.\n",
    "3. High resolution (250m) X-band radar data, merged with rain gauges.\n",
    "4. Merged Met Office radar data and quality controlled rain gauge data.\n",
    "5. Met Office radar data.\n",
    "6. Gridded quality controlled rain gauge data (IF Environment Agency rain gauge data exists).\n",
    "\n",
    "NOTE: 1. and 2. are missing as cannot test this whilst the Urban Observatory radar is down for maintenence and API is not working.\n",
    "\n",
    "### Prioritises data for input into SHETRAN model\n",
    "1. Merged Met Office radar data and quality controlled rain gauge data.\n",
    "2. Met Office radar data.\n",
    "3. Gridded quality controlled rain gauge data (IF Environment Agency rain gauge data exists). \n",
    "\n",
    "\n",
    "## File structure\n",
    "\n",
    "### Data inputs format \n",
    "- `\\inputs` - root inputs data folder\n",
    "\n",
    "### Data outputs format\n",
    "- `\\outputs` - root outputs data folder\n",
    "    - `\\SHETRAN` - SHETRAN rainfall input data, which should be in the correct format to run the model if running at 15 minute resolution (Note: We somehow need to add start date and data resolution into the library shetran set-up file I think).\n",
    "    - `\\HIPIMS` - HIPIMS rainfall input data, which should be in the correct format to run the model at 15 minute resolution\n",
    "\n",
    "## Data minimum requirements\n",
    "\n",
    "### Minimum data requirement to run model\n",
    "Either Met Office C-band radar data, or Environment Agency rain gauge data.\n",
    "\n",
    "\n",
    "- SHETRAN 1 and 2\n",
    "    1. Requirements:\n",
    "        - `\\input\\MET` exists and contains the files `arrays.npy`, `timestamp.csv`, `coords_x.csv` and `coords_y.csv`\n",
    "    2. Additional information if available:\n",
    "        - `\\input\\EA\\15min` exists and contains any `.csv` files\n",
    "        - `\\input\\UO\\15min` exists and contains any `.csv` files\n",
    "        - `\\input\\CS\\15min` exists and contains any `.csv` files\n",
    "        - `\\input\\NGIF\\15min` exists and contains any `.csv` files\n",
    "\n",
    "\n",
    "- SHETRAN 3\n",
    "    1. Requirements:\n",
    "        - `\\input\\EA\\15min` exists and contains more than one `.csv` file\n",
    "    2. Additional information if available:\n",
    "        - `\\input\\UO\\15min` exists and contains any `.csv` files\n",
    "        - `\\input\\CS\\15min` exists and contains any `.csv` files\n",
    "        - `\\input\\NGIF\\15min` exists and contains any `.csv` files\n",
    "\n",
    "\n",
    "- HIPIMS 1\n",
    "    1. Requirements:\n",
    "        - `\\input\\UO\\radar\\15min` exists and contains the files `arrays.npy`, `timestamp.csv`, `coords_x.csv` and `coords_y.csv`\n",
    "    - `\\input\\MET` exists and contains the files `arrays.npy`, `timestamp.csv`, `coords_x.csv` and `coords_y.csv`\n",
    "    2. Additional information if available:\n",
    "        - `\\input\\EA\\15min` exists and contains any `.csv` files\n",
    "        - `\\input\\UO\\15min` exists and contains any `.csv` files\n",
    "        - `\\input\\CS\\15min` exists and contains any `.csv` files\n",
    "        - `\\input\\NGIF\\15min` exists and contains any `.csv` files\n",
    "\n",
    "\n",
    "- HIPIMS 2\n",
    "    1. Requirements:\n",
    "        - `\\input\\UO\\radar\\15min` exists and contains the files `arrays.npy`, `timestamp.csv`, `coords_x.csv` and `coords_y.csv`\n",
    "        - `\\input\\MET` exists and contains the files `arrays.npy`, `timestamp.csv`, `coords_x.csv` and `coords_y.csv`\n",
    "    2. Additional information if available:\n",
    "        - `\\input\\EA\\15min` exists and contains any `.csv` files\n",
    "        - `\\input\\UO\\15min` exists and contains any `.csv` files\n",
    "        - `\\input\\CS\\15min` exists and contains any `.csv` files\n",
    "        - `\\input\\NGIF\\15min` exists and contains any `.csv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c034dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevent packages\n",
    "from os.path import join, exists, split\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import wradlib.ipol as ipol\n",
    "import gstools as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aecf6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths to change\n",
    "input_path = r\"C:\\Users\\Amy\\OneDrive - Newcastle University (1)\\Documents\\PYRAMID\\data\\realtime\"\n",
    "\n",
    "# output data paths\n",
    "output_path = input_path\n",
    "\n",
    "# Bounding box for data \n",
    "e_l, n_l, e_u, n_u = [355000, 534000, 440000, 609000]\n",
    "bbox = [e_l, e_u, n_l, n_u]\n",
    "res = 1000\n",
    "\n",
    "output_shetran_path = join(output_path, \"SHETRAN\")\n",
    "if not exists(output_shetran_path):\n",
    "    os.mkdir(output_shetran_path)\n",
    "\n",
    "output_hipims_path = join(output_path, \"HIPIMS\")\n",
    "if not exists(output_hipims_path):\n",
    "    os.mkdir(output_hipims_path)\n",
    "\n",
    "# path to files needed to clip data (e.g. bounding box for HIPIMS, mask file for SHETRAN)\n",
    "static_path = join(input_path, \"static\")\n",
    "\n",
    "# set up a function that reads the header lines from a SHETRAN mask:\n",
    "def read_ascii_header(file_path: str):\n",
    "\n",
    "    header_dict = {}\n",
    "    line=[]\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            line = line.split()\n",
    "            if len(line)>2: break\n",
    "            header_dict[line[0]] = float(line[1])\n",
    "\n",
    "    return header_dict\n",
    "    \n",
    "# path to SHETRAN mask (needs changing)\n",
    "shetran_mask_path = join(static_path, \"Tyne_at_Newcastle_Mask.asc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3684967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for reading in rain gauge data\n",
    "def read_gauges(source):\n",
    "    \n",
    "    gauges = []\n",
    "    \n",
    "    root_path = join(input_path, source)\n",
    "    folder_path = join(root_path, \"15min\")\n",
    "    \n",
    "    if exists(folder_path):\n",
    "\n",
    "        for f in os.listdir(folder_path):\n",
    "            if f.endswith(\".csv\"):\n",
    "                \n",
    "                data = pd.read_csv(join(folder_path, f), index_col=0)\n",
    "                data.index = pd.to_datetime(data.index, utc=True)\n",
    "                data.columns = [source + \"_\" + f.split(\".\")[0]]\n",
    "                gauges.append(data)\n",
    "                \n",
    "    return gauges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ca997c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amy\\AppData\\Local\\Temp\\ipykernel_16696\\829378489.py:28: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  gauges = pd.concat(gauges, 1)\n"
     ]
    }
   ],
   "source": [
    "met_path = join(join(input_path, \"MET\"), \"15min\")\n",
    "uo_path = join(input_path, \"UO\")\n",
    "uo_radar_path = join(join(uo_path, \"radar\"), \"15min\")\n",
    "\n",
    "shetran_method = np.nan\n",
    "hipims_method = np.nan\n",
    "\n",
    "radar_files = ['arrays.npy', 'coords_x.csv', 'coords_y.csv', 'timestamp.csv']\n",
    "if exists(met_path):\n",
    "    if all([f in os.listdir(met_path) for f in radar_files]):\n",
    "        \n",
    "        # try and read in Met Office weather radar data \n",
    "        met_radar = {}\n",
    "        for f in radar_files:\n",
    "            if f.endswith(\".csv\"):\n",
    "                data = pd.read_csv(join(met_path, f)).iloc[:, 0]\n",
    "            else:\n",
    "                data = np.load(join(met_path, f))\n",
    "\n",
    "            met_radar[f.split(\".\")[0]] = data\n",
    "        \n",
    "        # try and read in rain gauge data\n",
    "        gauges = []\n",
    "        for source in [\"EA\", \"CS\", \"UO\", \"NGIF\"]:\n",
    "            gauges.extend(read_gauges(source))\n",
    "\n",
    "        if len(gauges) > 0:\n",
    "            gauges = pd.concat(gauges, 1)\n",
    "            \n",
    "            # SHETRAN INPUT 1: merge radar and gauges together\n",
    "            shetran_method = 1\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # SHETRAN INPUT 2: just radar data\n",
    "            shetran_method = 2\n",
    "else:\n",
    "    \n",
    "    gauges = []\n",
    "    for source in [\"EA\", \"CS\", \"UO\", \"NGIF\"]:\n",
    "        gauges.extend(read_gauges(source))\n",
    "    if len(gauges) > 0:\n",
    "        gauges = pd.concat(gauges, 1)\n",
    "        \n",
    "        # check Environment Agency gauge data available\n",
    "        if sum([col.split(\"_\")[0] == \"EA\" for col in gauges.columns]) > 1: \n",
    "            \n",
    "            # SHETRAN INPUT 3: gridded rain gauge data\n",
    "            shetran_method = 3\n",
    "\n",
    "if exists(uo_radar_path):\n",
    "    \n",
    "    if all([f in os.listdir(uo_radar_path) for f in radar_files]):\n",
    "        \n",
    "        # try and read in Urban Observatory weather radar data \n",
    "        uo_radar = {}\n",
    "        for f in radar_files:\n",
    "            if f.endswith(\".csv\"):\n",
    "                data = pd.read_csv(join(uo_radar_path, f)).iloc[:, 0]\n",
    "            else:\n",
    "                data = np.load(join(uo_radar_path, f))\n",
    "\n",
    "            uo_radar[f.split(\".\")[0]] = data\n",
    "            \n",
    "        if uo_radar[\"arrays\"].shape[0] > 0:\n",
    "            \n",
    "            hipims_method = shetran_method\n",
    "            \n",
    "            # HIPIMS INPUT 1, 2 or 3: High-resolution X-band radar data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad84e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not np.isnan(hipims_method):\n",
    "    \n",
    "    if hipims_method == 1:\n",
    "        \n",
    "        # HIPIMS INPUT 1: High-resolution X-band radar data, merged with rain gauges, which is conditional on Met Office C-band radar data.\n",
    "        \n",
    "        \"\"\"\n",
    "        # NOTE: Code not written as high-resolution X-band radar data \n",
    "                was down for maintenence/broken for the duration of \n",
    "                the PYRAMID project, but this is where the code would\n",
    "                go for high resolution (250m) X-band radar data, merged \n",
    "                with rain gauges, which is conditional on Met Office \n",
    "                C-band radar data.\n",
    "                \n",
    "                If code is included, output should be a dictionary \n",
    "                named high_res_rainfall, with attributes mirroring \n",
    "                full_rainfall.\n",
    "        \"\"\"\n",
    "        \n",
    "    elif hipims_method == 2:\n",
    "        \n",
    "        # HIPIMS INPUT 2: High-resolution X-band radar data, conditional on Met Office C-band radar data\n",
    "        \n",
    "        \"\"\"\n",
    "        # NOTE: Code not written as high-resolution X-band radar data \n",
    "                was down for maintenence/broken for the duration of \n",
    "                the PYRAMID project, but this is where the code would\n",
    "                go for high resolution (250m) X-band radar data, \n",
    "                conditional on Met Office C-band radar data.\n",
    "                                \n",
    "                If code is included, output should be a dictionary \n",
    "                named high_res_rainfall, with attributes mirroring \n",
    "                full_rainfall.\n",
    "        \"\"\"\n",
    "        \n",
    "    elif hipims_method == 3:\n",
    "        \n",
    "        # HIPIMS INPUT 3: High-resolution X-band radar data, merged with rain gauges.\n",
    "        \n",
    "        \"\"\"\n",
    "        # NOTE: Code not written as high-resolution X-band radar data \n",
    "                was down for maintenence/broken for the duration of \n",
    "                the PYRAMID project, but this is where the code would\n",
    "                go for high resolution (250m) X-band radar data, \n",
    "                merged with rain gauges.\n",
    "                                \n",
    "                If code is included, output should be a dictionary \n",
    "                named high_res_rainfall, with attributes mirroring \n",
    "                full_rainfall.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ab3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up new coordinates for SHETRAN\n",
    "mask = np.loadtxt(shetran_mask_path, skiprows=6)\n",
    "\n",
    "# get mask meta info\n",
    "meta = read_ascii_header(shetran_mask_path)\n",
    "\n",
    "new_x = np.arange(meta[\"xllcorner\"], \n",
    "                  meta[\"xllcorner\"] + meta[\"ncols\"] * meta[\"cellsize\"],\n",
    "                  meta[\"cellsize\"])\n",
    "\n",
    "new_y = np.arange(meta[\"yllcorner\"], \n",
    "                  meta[\"yllcorner\"] + meta[\"nrows\"] * meta[\"cellsize\"],\n",
    "                  meta[\"cellsize\"])\n",
    "\n",
    "if not np.isnan(shetran_method):\n",
    "    if shetran_method == 1:\n",
    "\n",
    "        # SHETRAN INPUT 1: Merged Met Office radar data and quality controlled rain gauge data.\n",
    "        full_rainfall = {}\n",
    "        for attr in [\"timestamp\", \"coords_x\", \"coords_y\"]:\n",
    "            full_rainfall[attr] = met_radar[attr]\n",
    "\n",
    "        full_rainfall[\"arrays\"] = np.full(met_radar[\"arrays\"].shape, np.nan)\n",
    "\n",
    "        g_x = np.array([col.split(\"_\")[-2] for col in gauges.columns]).astype(float)\n",
    "        g_y = np.array([col.split(\"_\")[-1] for col in gauges.columns]).astype(float)\n",
    "\n",
    "        # source coordinates\n",
    "        src = np.vstack([g_x, g_y]).transpose()\n",
    "\n",
    "        # target coordinates\n",
    "        xtrg = full_rainfall[\"coords_x\"]\n",
    "        ytrg = np.flip(full_rainfall[\"coords_y\"]) # check this is correct way round\n",
    "\n",
    "        trg = np.meshgrid(xtrg, ytrg)\n",
    "        trg = np.vstack((trg[0].ravel(), trg[1].ravel())).T\n",
    "\n",
    "        for t in range(met_radar[\"arrays\"].shape[0]):\n",
    "            \n",
    "            rad = met_radar[\"arrays\"][t]\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                gau = np.array(gauges.iloc[t, :])\n",
    "\n",
    "                rad_x = [np.argmin(abs(x - met_radar[\"coords_x\"])) for x in g_x]\n",
    "                rad_y = [np.argmin(abs(y - np.flip(met_radar[\"coords_y\"]))) for y in g_y]\n",
    "\n",
    "                rad_at_g = np.array(rad[rad_y, rad_x])\n",
    "\n",
    "                try:\n",
    "                    # interpolation objects (Kriging with External Drift)\n",
    "                    if not np.isnan(np.nansum(rad_at_g)):\n",
    "                        ked = ipol.ExternalDriftKriging(src, trg, src_drift=rad_at_g, trg_drift=rad.flatten()) \n",
    "                        # should investigate further variogram structure for data\n",
    "                        # default set to cov='1.0 Exp(10000.)'\n",
    "                    else:\n",
    "                        ked = ipol.ExternalDriftKriging(src, trg)\n",
    "\n",
    "                    full_rainfall[\"arrays\"][t] = ked(gau).reshape(rad.shape) \n",
    "                \n",
    "                except:\n",
    "                    full_rainfall[\"arrays\"][t] = rad\n",
    "            \n",
    "            except:\n",
    "                full_rainfall[\"arrays\"][t] = rad\n",
    "                    \n",
    "    elif shetran_method == 2:\n",
    "\n",
    "        # SHETRAN INPUT 2: Met Office radar data.\n",
    "        full_rainfall = met_radar\n",
    "\n",
    "    elif shetran_method == 3:\n",
    "\n",
    "        # SHETRAN INPUT 3: Gridded quality controlled rain gauge data (IF Environment Agency rain gauge data exists). \n",
    "        full_rainfall = {}\n",
    "        full_rainfall[\"timestamp\"] = gauges.index\n",
    "\n",
    "        g_x = np.array([col.split(\"_\")[-2] for col in gauges.columns]).astype(float)\n",
    "        g_y = np.array([col.split(\"_\")[-1] for col in gauges.columns]).astype(float)\n",
    "\n",
    "        full_rainfall[\"coords_x\"] = new_x\n",
    "        full_rainfall[\"coords_y\"] = new_y\n",
    "\n",
    "        # source coordinates\n",
    "        src = np.vstack([g_x, g_y]).transpose()\n",
    "\n",
    "        # target coordinates\n",
    "        xtrg = full_rainfall[\"coords_x\"]\n",
    "        ytrg = full_rainfall[\"coords_y\"]\n",
    "        trg = np.meshgrid(xtrg, ytrg)\n",
    "        trg = np.vstack((trg[0].ravel(), trg[1].ravel())).T\n",
    "\n",
    "        # interpolation objects (Ordinary Kriging)\n",
    "        ok = ipol.OrdinaryKriging(src, trg, remove_missing=True)\n",
    "        ok1 = ipol.OrdinaryKriging(src[0:-1, :], trg, remove_missing=True)\n",
    "\n",
    "        gridded = np.full((len(gauges.index), len(ys), len(xs)), np.nan) # check dimensions correct way round\n",
    "\n",
    "        for t in range(len(gauges.index)):\n",
    "\n",
    "            vals = gauges.iloc[t].values\n",
    "            tot = np.nansum(vals)\n",
    "\n",
    "            if not np.isnan(tot):\n",
    "                if tot == 0:\n",
    "                    gridded[t] = 0\n",
    "                else:\n",
    "                    try:\n",
    "                        gridded[t] = np.flip(ok(vals).astype(float).reshape((len(ys), len(xs))), axis=0)\n",
    "                    except:\n",
    "                        pass    \n",
    "\n",
    "        full_rainfall[\"arrays\"] = gridded\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # INSUFFICIENT DATA FOR THE CODE TO RUN\n",
    "    print(\"Insufficient data for the code to run. Stop the workflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "84d71515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip to SHETRAN domain and save\n",
    "\n",
    "output_shetran_full = np.full(\n",
    "    (full_rainfall[\"arrays\"].shape[0], \n",
    "     new_y.shape[0], \n",
    "     new_x.shape[0]), np.nan)\n",
    "\n",
    "xs = full_rainfall[\"coords_x\"].values\n",
    "ys = np.flip(full_rainfall[\"coords_y\"].values)\n",
    "\n",
    "new_x_cond = np.array([min(abs(x - xs)) < 500 for x in new_x])\n",
    "new_y_cond = np.array([min(abs(y - ys)) < 500 for y in new_y])\n",
    "\n",
    "old_x_cond = np.array([min(abs(x - new_x)) < 500 for x in xs])\n",
    "old_y_cond = np.array([min(abs(y - new_y)) < 500 for y in ys])\n",
    "\n",
    "if not all(old_y_cond):\n",
    "    input1 = full_rainfall[\"arrays\"][:, old_y_cond, :]\n",
    "else:\n",
    "    input1 = full_rainfall[\"arrays\"]\n",
    "    \n",
    "if not all(old_x_cond):\n",
    "    input2 = input1[:, :, old_x_cond]\n",
    "else:\n",
    "    input2 = input1\n",
    "\n",
    "if all(new_x_cond) and all(new_y_cond):\n",
    "    output_shetran_full = input2\n",
    "elif all(new_x_cond):\n",
    "    output_shetran_full[:, new_y_cond, :] = input2\n",
    "else:\n",
    "    output_shetran_full[:, new_y_cond, :][:, :, new_x_cond] = input2\n",
    "\n",
    "output_shetran = pd.DataFrame(output_shetran_full[:, mask == 0])\n",
    "output_shetran.to_csv(join(output_shetran_path, \"Tyne_at_Newcastle_Precip.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "11f30bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip data to HIPIMS domain and save\n",
    "\n",
    "# path to HIPIMS bbox file\n",
    "hipims_bbox_path = join(static_path, \"boundbox.shp\")\n",
    "bbox = gpd.read_file(hipims_bbox_path)\n",
    "\n",
    "# reproject bouninging box for data\n",
    "bbox['geometry'] = bbox['geometry'].to_crs(epsg=27700)\n",
    "min_x, min_y, max_x, max_y = bbox.bounds.loc[0]\n",
    "\n",
    "if not np.isnan(hipims_method):\n",
    "    \n",
    "    # high-resolution data \n",
    "    try:\n",
    "        \"\"\"\n",
    "        Note: This does not work as high_res_rainfall dictionary \n",
    "        not defined as code does not existdo to maintence issues \n",
    "        of high resolution X-band radar data at Urban Observatory.\n",
    "        \"\"\"\n",
    "        \n",
    "        xs = high_res_rainfall[\"coords_x\"]\n",
    "        ys = high_res_rainfall[\"coords_y\"]\n",
    "        arrs = high_res_rainfall[\"arrays\"]\n",
    "        \n",
    "    except:\n",
    "        print(\"High resolution rainfall does not exist.\")\n",
    "        xs = full_rainfall[\"coords_x\"]\n",
    "        ys = full_rainfall[\"coords_y\"]\n",
    "        arrs = full_rainfall[\"arrays\"]\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # no high-resolution data\n",
    "    xs = full_rainfall[\"coords_x\"]\n",
    "    ys = full_rainfall[\"coords_y\"]\n",
    "    arrs = full_rainfall[\"arrays\"]\n",
    "    \n",
    "    \n",
    "x_cond = (xs >= min_x - 500) & (xs <= max_x + 500)\n",
    "y_cond = (ys >= min_y - 500) & (ys <= max_y + 500)\n",
    "clip_x = arrs[:, :, x_cond]\n",
    "clipped_rainfall = clip_x[:, y_cond[::-1], :]\n",
    "\n",
    "# Reformat to dataframe for input file\n",
    "data = clipped_rainfall.reshape(clipped_rainfall.shape[0], clipped_rainfall.shape[1] * clipped_rainfall.shape[2])\n",
    "clipped_rainfall_hipims = pd.DataFrame(data, index=full_rainfall[\"timestamp\"])\n",
    "\n",
    "# Save file\n",
    "clipped_rainfall_hipims.to_csv(join(output_hipims_path, \"rain_source.txt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

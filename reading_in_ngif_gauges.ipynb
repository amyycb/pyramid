{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea567bfa",
   "metadata": {},
   "source": [
    "# Reading in Urban Observatory rain gauge data (1-5 min)\n",
    "\n",
    "### Notes\n",
    "- Intense QC code read in, not sure how easy that will be, I had to clone it off Github and change line 10 of code as got an error with a package, proabbly due to Python versions. Think the package needs updating on Github but not sure who is still in charge of maintaining it. Need ETCCDI data (available in example data for Intense QC)\n",
    "\n",
    "\n",
    "### What does the code do\n",
    "\n",
    "### What does the code need to do?\n",
    "1. Download the data\n",
    "    - Try API\n",
    "    - Sort out problems with wrong accumulation methods\n",
    "    - Save data\n",
    "2. Quality control data\n",
    "    - Use intense-qc code\n",
    "    - Remove failed gauges\n",
    "    - Remove failed observations\n",
    "    - Save Qc'ed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44cda4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevent packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from os.path import join, exists\n",
    "import os\n",
    "from datetime import datetime\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a8da106",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Inputs to change\n",
    "start_date = \"2023-06-20\"\n",
    "end_date = \"2023-06-30\"\n",
    "\n",
    "out_path = r\"C:\\Users\\Amy\\OneDrive - Newcastle University (1)\\Documents\\PYRAMID\\data\\realtime\"\n",
    "\n",
    "# Bounding box for data \n",
    "e_l, n_l, e_u, n_u = [355000, 534000, 440000, 609000]\n",
    "#lon_l, lat_l, lon_u, lat_u = [-2.6771176, 54.702623, -1.3749203, 55.361917]\n",
    "bbox = [e_l, e_u, n_l, n_u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70066f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngif_outpath = join(out_path, \"NGIF\")\n",
    "if not exists(ngif_outpath):\n",
    "    os.mkdir(ngif_outpath)\n",
    "\n",
    "# Get list of rainfall stations\n",
    "easting = \"424038\"\n",
    "northing = \"564414\"\n",
    "sensor_loc = \"Ensemble E Pit Gauge\"\n",
    "sensor_id = \"Pit rain gauge\"\n",
    "sensor = sensor_loc.replace(\" \", \"-\")\n",
    "\n",
    "# convert timestamp\n",
    "start_time = pd.to_datetime(start_date)\n",
    "end_time = pd.to_datetime(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5ed8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start_time, end_time)\n",
    "dates = dates.format(\"%f\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5676bcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amy\\anaconda3\\envs\\wradlib\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ngif.newcastle.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\Amy\\anaconda3\\envs\\wradlib\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ngif.newcastle.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\Amy\\anaconda3\\envs\\wradlib\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ngif.newcastle.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\Amy\\anaconda3\\envs\\wradlib\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ngif.newcastle.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 2023-06-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amy\\anaconda3\\envs\\wradlib\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ngif.newcastle.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 2023-06-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amy\\anaconda3\\envs\\wradlib\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ngif.newcastle.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 2023-06-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amy\\anaconda3\\envs\\wradlib\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ngif.newcastle.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 2023-06-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amy\\anaconda3\\envs\\wradlib\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ngif.newcastle.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 2023-06-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amy\\anaconda3\\envs\\wradlib\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ngif.newcastle.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\Amy\\anaconda3\\envs\\wradlib\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ngif.newcastle.ac.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tabs = []\n",
    "\n",
    "for i in range(len(dates) - 1):\n",
    "    path = \"https://ngif.newcastle.ac.uk/download/Ensemble%20E/Pit%20Rain%20Gauge%23%401m/\" + dates[i] + \"/\" + dates[i + 1]\n",
    "    try:\n",
    "        r = requests.get(path, verify=False)\n",
    "        tab = pd.read_csv(io.StringIO(r.text))\n",
    "        if tab.shape[0] > 0:\n",
    "            tabs.append(tab)\n",
    "    except:\n",
    "        print(\"Failed\", dates[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5acc750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabs = pd.concat(tabs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e9b1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_res = 0.2 * pd.Series(tabs[tabs.columns[1]].values, index = pd.to_datetime(tabs.time))\n",
    "high_res.index = high_res.index.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3bef53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = high_res.resample(str(60*15) + \"s\").sum() * 4 # 15 min resolution\n",
    "high_res.to_csv(join(ngif_outpath, sensor + \"_\" + str(easting) + \"_\" + str(northing) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ece18c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevent packages\n",
    "import os\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "os.sys.path.append(r\"C:\\Users\\Amy\\OneDrive - Newcastle University (1)\\Documents\\Jupyter\\intense-qc\")\n",
    "from intense import gauge, qc, utils\n",
    "from pyproj import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77314ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inputs to change\n",
    "gauge_path = join(out_path, \"NGIF\")\n",
    "etccdi_data_folder = r\"C:\\Users\\Amy\\OneDrive - Newcastle University (1)\\Documents\\Jupyter\\intense-qc\\tests\\etccdi_data\"\n",
    "\n",
    "gauge_files = [f for f in os.listdir(gauge_path) if f.endswith(\".csv\")]\n",
    "\n",
    "gauges = {}\n",
    "\n",
    "for g in gauge_files:\n",
    "    name = g[0:-4]\n",
    "    data_raw = pd.read_csv(join(gauge_path, g), index_col=0, parse_dates=True).iloc[:, 0]\n",
    "    data_raw = data_raw.sort_index()\n",
    "    res_min = pd.Series(data_raw.dropna().index).diff().median().seconds / 60\n",
    "    \n",
    "    data = data_raw.resample(str(60*15) + \"s\").sum() * 4 # gives mm/h every 15 min\n",
    "    \n",
    "    try:\n",
    "        if data.index.dtype == \"datetime64[ns, UTC]\":\n",
    "            gauges[name] = data.resample(\"1h\").sum()\n",
    "        else:\n",
    "            gauges[name] = data.resample(\"1h\").sum().tz_localize('UTC')\n",
    "    except:\n",
    "        print(name, \"not read in.\")\n",
    "\n",
    "gauges = pd.DataFrame(gauges)\n",
    "gauges = gauges.dropna(axis=0, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c1c6b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gauge_flags(data, loc):\n",
    "    '''Function to apply wokring Intense QC hourly checks on gauge data. \n",
    "    Args: data is the gauge data (pd.Series), loc is the gauge location (eastings, northings)\n",
    "    Returns: flags as a dictionary {gauge flagged, years flagged, obs flagged}\n",
    "    '''\n",
    "    eastings, northings = loc\n",
    "    # convert coordinates to lat/lon\n",
    "    transformer = Transformer.from_crs(\"epsg:27700\", \"epsg:4326\")\n",
    "    latitude, longitude = transformer.transform(eastings, northings)\n",
    "\n",
    "    # create gauge object\n",
    "    rain_gauge = gauge.Gauge(\n",
    "        station_id,\n",
    "        path_to_original_data=\"\",\n",
    "        latitude=latitude,\n",
    "        longitude=longitude,\n",
    "        original_timestep=\"15min\",\n",
    "        original_units=\"mm/h\",\n",
    "        new_units=\"mm/h\",\n",
    "        new_timestep=\"1h\",\n",
    "        data=data\n",
    "    )\n",
    "    rain_gauge.get_info()\n",
    "\n",
    "    # create qc object \n",
    "    test = qc.Qc(\n",
    "        gauge=rain_gauge,\n",
    "        etccdi_data_folder=etccdi_data_folder\n",
    "    )\n",
    "\n",
    "    # checks that don't work on existing data\n",
    "    \"\"\"\n",
    "    test.check_percentiles()\n",
    "    test.check_k_largest()\n",
    "    test.check_intermittency()\n",
    "    test.change_in_min_val_check() \n",
    "    test.cwd_check() # missing function in utils file???\n",
    "    test.change_in_min_val_check() # Change in minimum value check, homogeneity check to see if the resolution of the data has changed. Change flag, flag years\n",
    "    test.find_neighbours(\"hourly\") # frequency: must be either hourly, daily or monthly, Names or names and paths of neighbouring stations\n",
    "    # conditions are: must be within 50km, at least 3 years overlap, select the closest 10, don't have three years of data\n",
    "    # check_hourly_neighbours(), check_daily_neighbours(), check_monthly_neighbours()\n",
    "    test.get_flags() # runs all checks, fails at find_neighbours()\n",
    "    \"\"\"\n",
    "\n",
    "    ### run checks ###\n",
    "\n",
    "    flagged_sdii = 0\n",
    "    sdii_thresh = 100 # just arbitrary atm\n",
    "    if any(np.array(test.get_sdii()) > sdii_thresh): # Simple precipitation intensity index, SDII from ETCCDI and from gauge values (sdii_gridded, sdii_gauge), not sure how to use this\n",
    "        flagged_sdii = 1\n",
    "    \n",
    "    # Flag data if any of these don't return 0:\n",
    "    gauge_checks = [\n",
    "        test.check_days_of_week(), # Checks if proportions of rainfall in each day is significantly different\n",
    "        test.check_break_point(), # Pettitt breakpoint check\n",
    "        flagged_sdii\n",
    "    ]\n",
    "    \n",
    "    flagged_gauge = sum(gauge_checks) != 0\n",
    "    #if flagged_gauge:\n",
    "    #    print(\"Gauge\", np.array([\"days of week\", \"break point\", \"sdii\"])[np.array(gauge_checks) == 1])\n",
    "    #    print(test.check_break_point())\n",
    "\n",
    "    # Flag individual data observations if don't return 0:\n",
    "    obs_checks = pd.DataFrame(index=rain_gauge.data.index)\n",
    "    obs_checks[\"world_record\"] = test.world_record_check_ts() # Checks if and to what degree the world record has been exceeded by each rainfall value, 4, 3, 2 or 1 if exceeded by > 1.5x, 1.33x, 1.22x or 0x respectively and 0 if not exceeded for each value\n",
    "    obs_checks[\"rx1day\"] = test.rx1day_check_ts() # Checks hourly values against maximum 1-day precipitation, Magnitudes of exceedance for each day\n",
    "    obs_checks[\"cdd\"] = test.cdd_check() # ETCCDI provide an index for maximum length of dry spell. Look for suspicious number of consecutive dry hours recorded. Consecutive Dry Days: Maximum length of dry spell, maximum number of consecutive days with RR < 1mm. Magnitudes of exceedence of the length of longest dry period\n",
    "    obs_checks[\"daily_accums\"] = test.daily_accums_check() # Check daily accumulations. Suspect daily accumulations flagged where a recorded rainfall amount at these times is preceded by 23 hours with no rain. A threshold of 2x the mean wet day amount for the corresponding month is applied to increase thechance of identifying accumulated values at the expense of genuine, moderate events\n",
    "    obs_checks[\"monthly_accums\"] = test.monthly_accums_check() # Check monthly accumulations. Flags month prior to high value\n",
    "    obs_checks[\"streaks\"] = test.streaks_check() # Streaks: This is where you see the same value repeated in a run. Currently this records streaks of 2hrs in a row or more over 2 x Monthly mean rainfall. It is considered to be unlikely that you would see even 2 consecutive large rainfall amounts. For this code I have substituted the monthly mean rainfall for SDII as I want the thresholds to be independent of the rainfall time series as the global dataset is of highly variable quality.\n",
    "    flagged_obs = obs_checks.index[obs_checks.sum(1) > 0]\n",
    "\n",
    "    # Flags each individual year:\n",
    "    year_flags = np.array([\n",
    "        test.r99ptot_check_annual(), # Check against R99pTOT: R99pTOT. Annual total PRCP when RR > 99p. Magnitudes of exceedance for yearly 99th percentiles\n",
    "        test.prcptot_check_annual() # check against annual total: PRCPTOT. Annual total precipitation in wet days. Magnitudes of exceedance for yearly totals\n",
    "    ])\n",
    "\n",
    "    flagged_years = np.arange(rain_gauge.data.index.min().year, rain_gauge.data.index.max().year + 1)[year_flags.sum(0) < 0]\n",
    "\n",
    "    return({\"gauge\" : flagged_gauge, \"years\" : flagged_years, \"obs\" : flagged_obs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fb236de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amy\\OneDrive - Newcastle University (1)\\Documents\\Jupyter\\intense-qc\\intense\\qc.py:817: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df3 = df1.append(df2)\n"
     ]
    }
   ],
   "source": [
    "qc_gauges = pd.DataFrame(index=gauges.index)\n",
    "for i in range(len(gauges.columns)):\n",
    "    col = gauges.columns[i]\n",
    "    station_id, eastings, northings = col.split(\"_\")\n",
    "\n",
    "    data = gauges.iloc[:, i].dropna()\n",
    "    loc = (eastings, northings)\n",
    "\n",
    "    flags = get_gauge_flags(data, loc)\n",
    "\n",
    "    # only include gauge data that is not flagged\n",
    "    if not flags[\"gauge\"]:\n",
    "\n",
    "        # currenly ignoring year flag as not enough data\n",
    "\n",
    "        # remove flagged observationns\n",
    "        if len(flags[\"obs\"]) < 0:\n",
    "            qc_gauges[col] = gauges[col]\n",
    "        else:\n",
    "            obs_cond = [t not in flags[\"obs\"] for t in gauges.index]\n",
    "            qc_gauges[col] = np.nan\n",
    "            \n",
    "            qc_gauges.loc[obs_cond, col] = gauges.loc[obs_cond, col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cbf6e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_path = join(gauge_path, \"qc\")\n",
    "if not exists(qc_path):\n",
    "    os.mkdir(qc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "26af6e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in qc_gauges.columns:\n",
    "    data = qc_gauges[col].dropna()\n",
    "    if len(data) > 0:\n",
    "        data.to_csv(join(qc_path, col + \".csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

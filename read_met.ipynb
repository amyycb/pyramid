{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "655af1c5",
   "metadata": {},
   "source": [
    "# Reading in Met Office C-band composite radar data\n",
    "\n",
    "### Notes\n",
    "- Large chunk of messy Met Office code at the beginning.\n",
    "- The ftp server currently has my username and password for CEDA, this is going to need changing, maybe set up an account for PYRAMID.\n",
    "- This is currently set to get the rainfall data (gridded composite radar 1km resolution data) for the Toon Monsoon rainfall event for Newcastle upon Tyne.\n",
    "- TO DO: Create requirements.txt.\n",
    "\n",
    "\n",
    "### What does the code do?\n",
    "1. Creates a list of file names (daily) to look for on the ftp server.\n",
    "2. Downloads daily .tar files.\n",
    "3. Unzips the files and extracts 5min .dat files.\n",
    "4. Uses Met Office code to read in the .dat files, and clips using specified bounding box.\n",
    "5. Saves the raw 5 and 15 min files (just as .npy files, I would usually save them as .h5 files however I don't think at any point the data will get too big at the moment.\n",
    "\n",
    "\n",
    "### Outputs format\n",
    "- `\\root` folder path \n",
    "    - `\\MET` folder path (5 minute radar data)\n",
    "        - `arrays.npy` - radar data arrays (t, y, x)\n",
    "        - `timestamp.csv`- radar data timestamp\n",
    "        - `coords_x.csv` - radar data x-coordinates\n",
    "        - `coords_y.csv` - radar data y-coordinates\n",
    "        - `\\15min` folder path (15 minute radar data)\n",
    "            - `arrays.npy` - radar data arrays (t, y, x)\n",
    "            - `timestamp.csv`- radar data timestamp\n",
    "            - `coords_x.csv` - radar data x-coordinates\n",
    "            - `coords_y.csv` - radar data y-coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d14a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import struct\n",
    "import array\n",
    "from os.path import join, exists\n",
    "import os\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import h5py\n",
    "import shapefile\n",
    "import pandas as pd\n",
    "import os\n",
    "import ftplib\n",
    "import gzip\n",
    "import tarfile\n",
    "from os.path import join\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9ebd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################    MET OFFICE CODE    ############################\n",
    "\n",
    "class Nimrod:\n",
    "    \"\"\"Reading, querying and processing of NIMROD format rainfall data files.\"\"\"\n",
    "\n",
    "    class RecordLenError(Exception):\n",
    "        \"\"\"S\n",
    "        Exception Type: NIMROD record length read from file not as expected.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, actual, expected, location):\n",
    "            self.message = (\n",
    "                    \"Incorrect record length %d bytes (expected %d) at %s.\"\n",
    "                    % (actual, expected, location))\n",
    "\n",
    "    class HeaderReadError(Exception):\n",
    "        \"\"\"Exception Type: Read error whilst parsing NIMROD header elements.\"\"\"\n",
    "        pass\n",
    "\n",
    "    class PayloadReadError(Exception):\n",
    "        \"\"\"Exception Type: Read error whilst parsing NIMROD raster data.\"\"\"\n",
    "        pass\n",
    "\n",
    "    class BboxRangeError(Exception):\n",
    "        \"\"\"\n",
    "        Exception Type: Bounding box specified out of range of raster image.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def __init__(self, infile):\n",
    "        \"\"\"\n",
    "        Parse all header and data info from a NIMROD data file into this object.\n",
    "        (This method based on read_nimrod.py by Charles Kilburn Aug 2008)\n",
    "\n",
    "        Args:\n",
    "            infile: NIMROD file object opened for binary reading\n",
    "        Raises:\n",
    "            RecordLenError: NIMROD record length read from file not as expected\n",
    "            HeaderReadError: Read error whilst parsing NIMROD header elements\n",
    "            PayloadReadError: Read error whilst parsing NIMROD raster data\n",
    "        \"\"\"\n",
    "\n",
    "        def check_record_len(infile, expected, location):\n",
    "            \"\"\"\n",
    "            Check record length in C struct is as expected.\n",
    "\n",
    "            Args:\n",
    "                infile: file to read from\n",
    "                expected: expected value of record length read\n",
    "                location: description of position in file (for reporting)\n",
    "            Raises:\n",
    "                HeaderReadError: Read error whilst reading record length\n",
    "                RecordLenError: Unexpected NIMROD record length read from file\n",
    "            \"\"\"\n",
    "\n",
    "            # Unpack length from C struct (Big Endian, 4-byte long)\n",
    "            try:\n",
    "                record_length, = struct.unpack(\">l\", infile.read(4))\n",
    "            except Exception:\n",
    "                raise Nimrod.HeaderReadError\n",
    "            if record_length != expected:\n",
    "                raise Nimrod.RecordLenError(record_length, expected, location)\n",
    "\n",
    "        # Header should always be a fixed length record\n",
    "        check_record_len(infile, 512, \"header start\")\n",
    "\n",
    "        # try:\n",
    "        # Read first 31 2-byte integers (header fields 1-31)\n",
    "        gen_ints = array.array(\"h\")\n",
    "        gen_ints.fromfile(infile, 31)\n",
    "        gen_ints.byteswap()\n",
    "\n",
    "        # Read next 28 4-byte floats (header fields 32-59)\n",
    "        gen_reals = array.array(\"f\")\n",
    "        gen_reals.fromfile(infile, 28)\n",
    "        gen_reals.byteswap()\n",
    "\n",
    "        # Read next 45 4-byte floats (header fields 60-104)\n",
    "        spec_reals = array.array(\"f\")\n",
    "        spec_reals.fromfile(infile, 45)\n",
    "        spec_reals.byteswap()\n",
    "\n",
    "        # Read next 56 characters (header fields 105-107)\n",
    "        characters = array.array(\"b\")\n",
    "        characters.fromfile(infile, 56)\n",
    "\n",
    "        # Read next 51 2-byte integers (header fields 108-)\n",
    "        spec_ints = array.array(\"h\")\n",
    "        spec_ints.fromfile(infile, 51)\n",
    "        spec_ints.byteswap()\n",
    "        # except Exception:\n",
    "        #     infile.close()\n",
    "        #     raise Nimrod.HeaderReadError\n",
    "\n",
    "        check_record_len(infile, 512, \"header end\")\n",
    "\n",
    "        # Extract strings and make duplicate entries to give meaningful names\n",
    "        chars = characters.tobytes()\n",
    "        self.units = chars[0:8]\n",
    "        self.data_source = chars[8:32]\n",
    "        self.title = chars[32:55]\n",
    "\n",
    "        # Store header values in a list so they can be indexed by \"element\n",
    "        # number\" shown in NIMROD specification (starts at 1)\n",
    "        self.hdr_element = [None]  # Dummy value at element 0\n",
    "        self.hdr_element.extend(gen_ints)\n",
    "        self.hdr_element.extend(gen_reals)\n",
    "        self.hdr_element.extend(spec_reals)\n",
    "        self.hdr_element.extend([self.units])\n",
    "        self.hdr_element.extend([self.data_source])\n",
    "        self.hdr_element.extend([self.title])\n",
    "        self.hdr_element.extend(spec_ints)\n",
    "\n",
    "        # Duplicate some of values to give more meaningful names\n",
    "        self.nrows = self.hdr_element[16]\n",
    "        self.ncols = self.hdr_element[17]\n",
    "        self.n_data_specific_reals = self.hdr_element[22]\n",
    "        self.n_data_specific_ints = self.hdr_element[23] + 1\n",
    "        # Note \"+ 1\" because header value is count from element 109\n",
    "        self.y_top = self.hdr_element[34]\n",
    "        self.y_pixel_size = self.hdr_element[35]\n",
    "        self.x_left = self.hdr_element[36]\n",
    "        self.x_pixel_size = self.hdr_element[37]\n",
    "\n",
    "        # Calculate other image bounds (note these are pixel centres)\n",
    "        self.x_right = (self.x_left + self.x_pixel_size * (self.ncols - 1))\n",
    "        self.y_bottom = (self.y_top - self.y_pixel_size * (self.nrows - 1))\n",
    "\n",
    "        # Read payload (actual raster data)\n",
    "        array_size = self.ncols * self.nrows\n",
    "        check_record_len(infile, array_size * 2, \"data start\")\n",
    "\n",
    "        self.data = array.array(\"h\")\n",
    "        try:\n",
    "            self.data.fromfile(infile, array_size)\n",
    "            self.data.byteswap()\n",
    "        except Exception:\n",
    "            infile.close()\n",
    "            raise Nimrod.PayloadReadError\n",
    "\n",
    "        check_record_len(infile, array_size * 2, \"data end\")\n",
    "        infile.close()\n",
    "\n",
    "    def query(self):\n",
    "        \"\"\"Print complete NIMROD file header information.\"\"\"\n",
    "\n",
    "        print(\"NIMROD file raw header fields listed by element number:\")\n",
    "        print(\"General (Integer) header entries:\")\n",
    "        for i in range(1, 32):\n",
    "            print(\" \", i, \"\\t\", self.hdr_element[i])\n",
    "        print(\"General (Real) header entries:\")\n",
    "        for i in range(32, 60):\n",
    "            print(\" \", i, \"\\t\", self.hdr_element[i])\n",
    "        print((\"Data Specific (Real) header entries (%d):\"\n",
    "               % self.n_data_specific_reals))\n",
    "        for i in range(60, 60 + self.n_data_specific_reals):\n",
    "            print(\" \", i, \"\\t\", self.hdr_element[i])\n",
    "        print((\"Data Specific (Integer) header entries (%d):\"\n",
    "               % self.n_data_specific_ints))\n",
    "        for i in range(108, 108 + self.n_data_specific_ints):\n",
    "            print(\" \", i, \"\\t\", self.hdr_element[i])\n",
    "        print(\"Character header entries:\")\n",
    "        print(\"  105 Units:           \", self.units)\n",
    "        print(\"  106 Data source:     \", self.data_source)\n",
    "        print(\"  107 Title of field:  \", self.title)\n",
    "\n",
    "        # Print out info & header fields\n",
    "        # Note that ranges are given to the edge of each pixel\n",
    "        print(\"\\nValidity Time:  %2.2d:%2.2d on %2.2d/%2.2d/%4.4d\" % (\n",
    "            self.hdr_element[4], self.hdr_element[5],\n",
    "            self.hdr_element[3], self.hdr_element[2], self.hdr_element[1]))\n",
    "        print((\"Easting range:  %.1f - %.1f (at pixel steps of %.1f)\"\n",
    "               % (self.x_left - self.x_pixel_size / 2,\n",
    "                  self.x_right + self.x_pixel_size / 2, self.x_pixel_size)))\n",
    "        print((\"Northing range: %.1f - %.1f (at pixel steps of %.1f)\"\n",
    "               % (self.y_bottom - self.y_pixel_size / 2,\n",
    "                  self.y_top + self.y_pixel_size / 2, self.y_pixel_size)))\n",
    "        print(\"Image size: %d rows x %d cols\" % (self.nrows, self.ncols))\n",
    "\n",
    "    def apply_bbox(self, xmin, xmax, ymin, ymax):\n",
    "        \"\"\"\n",
    "        Clip raster data to all pixels that intersect specified bounding box.\n",
    "\n",
    "        Note that existing object data is modified and all header values\n",
    "        affected are appropriately adjusted. Because pixels are specified by\n",
    "        their centre points, a bounding box that comes within half a pixel\n",
    "        width of the raster edge will intersect with the pixel.\n",
    "\n",
    "        Args:\n",
    "            xmin: Most negative easting or longitude of bounding box\n",
    "            xmax: Most positive easting or longitude of bounding box\n",
    "            ymin: Most negative northing or latitude of bounding box\n",
    "            ymax: Most positive northing or latitude of bounding box\n",
    "        Raises:\n",
    "            BboxRangeError: Bounding box specified out of range of raster image\n",
    "        \"\"\"\n",
    "\n",
    "        # Check if there is no overlap of bounding box with raster\n",
    "        if (\n",
    "                xmin > self.x_right + self.x_pixel_size / 2 or\n",
    "                xmax < self.x_left - self.x_pixel_size / 2 or\n",
    "                ymin > self.y_top + self.y_pixel_size / 2 or\n",
    "                ymax < self.y_bottom - self.x_pixel_size / 2):\n",
    "            raise Nimrod.BboxRangeError\n",
    "\n",
    "        # Limit bounds to within raster image\n",
    "        xmin = max(xmin, self.x_left)\n",
    "        xmax = min(xmax, self.x_right)\n",
    "        ymin = max(ymin, self.y_bottom)\n",
    "        ymax = min(ymax, self.y_top)\n",
    "\n",
    "        # Calculate min and max pixel index in each row and column to use\n",
    "        # Note addition of 0.5 as x_left location is centre of pixel\n",
    "        # ('int' truncates floats towards zero)\n",
    "        xMinPixelId = int((xmin - self.x_left) / self.x_pixel_size + 0.5)\n",
    "        xMaxPixelId = int((xmax - self.x_left) / self.x_pixel_size + 0.5)\n",
    "\n",
    "        # For y (northings), note the first data row stored is most north\n",
    "        yMinPixelId = int((self.y_top - ymax) / self.y_pixel_size + 0.5)\n",
    "        yMaxPixelId = int((self.y_top - ymin) / self.y_pixel_size + 0.5)\n",
    "\n",
    "        bbox_data = []\n",
    "        for i in range(yMinPixelId, yMaxPixelId + 1):\n",
    "            bbox_data.extend(self.data[i * self.ncols + xMinPixelId:\n",
    "                                       i * self.ncols + xMaxPixelId + 1])\n",
    "\n",
    "        # Update object where necessary\n",
    "        self.data = bbox_data\n",
    "        self.x_right = self.x_left + xMaxPixelId * self.x_pixel_size\n",
    "        self.x_left += xMinPixelId * self.x_pixel_size\n",
    "        self.ncols = xMaxPixelId - xMinPixelId + 1\n",
    "        self.y_bottom = self.y_top - yMaxPixelId * self.y_pixel_size\n",
    "        self.y_top -= yMinPixelId * self.y_pixel_size\n",
    "        self.nrows = yMaxPixelId - yMinPixelId + 1\n",
    "        self.hdr_element[16] = self.nrows\n",
    "        self.hdr_element[17] = self.ncols\n",
    "        self.hdr_element[34] = self.y_top\n",
    "        self.hdr_element[36] = self.x_left\n",
    "\n",
    "    def extract_asc(self, outfile):\n",
    "        \"\"\"\n",
    "        Write raster data to an ESRI ASCII (.asc) format file.\n",
    "\n",
    "        Args:\n",
    "            outfile: file object opened for writing text\n",
    "        \"\"\"\n",
    "\n",
    "        # As ESRI ASCII format only supports square pixels, warn if not so\n",
    "        if self.x_pixel_size != self.y_pixel_size:\n",
    "            print((\"Warning: x_pixel_size(%d) != y_pixel_size(%d)\"\n",
    "                   % (self.x_pixel_size, self.y_pixel_size)))\n",
    "\n",
    "        # Write header to output file. Note that data is valid at the centre\n",
    "        # of each pixel so \"xllcenter\" rather than \"xllcorner\" must be used\n",
    "        outfile.write(\"xmin: \" + str(self.x_left) + \" \\n\")\n",
    "        outfile.write(\"xmax: \" + str(self.x_right) + \" \\n\")\n",
    "        outfile.write(\"ymin: \" + str(self.y_bottom) + \" \\n\")\n",
    "        outfile.write(\"ymax: \" + str(self.y_top) + \" \\n\")\n",
    "        outfile.write(\"ncols: \" + str(self.ncols) + \" \\n\")\n",
    "        outfile.write(\"nrows: \" + str(self.nrows) + \" \\n\")\n",
    "        outfile.write(\"cellsize : \" + str(self.y_pixel_size) + \" \\n\")\n",
    "        outfile.write(\"na_value: \" + str(self.hdr_element[38]) + \" \\n\")\n",
    "\n",
    "        # Write raster data to output file\n",
    "        for i in range(self.nrows):\n",
    "            for j in range(self.ncols - 1):\n",
    "                outfile.write(\"%d \" % self.data[i * self.ncols + j])\n",
    "            outfile.write(\"%d\\n\" % self.data[i * self.ncols + self.ncols - 1])\n",
    "        outfile.close()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Handle if called as a command line script\n",
    "# (And as an example of how to invoke class methods from an importing module)\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "def nimrod_file(file_in, file_out=None, bbox=None, query=False, extract=False):\n",
    "    try:\n",
    "        rainfall_data = Nimrod(open(file_in, 'rb'))\n",
    "        # rainfall_data = Nimrod(file_in)\n",
    "    except Nimrod.RecordLenError as error:\n",
    "        sys.stderr.write(\"ERROR: %s\\n\" % error.message)\n",
    "        sys.exit(1)\n",
    "\n",
    "    if bbox is not None:\n",
    "        #sys.stderr.write(\n",
    "        #    \"Trimming NIMROD raster to bounding box...\\n\")\n",
    "        try:\n",
    "            rainfall_data.apply_bbox(bbox[0], bbox[1], bbox[2], bbox[3])\n",
    "        except Nimrod.BboxRangeError:\n",
    "            sys.stderr.write(\"ERROR: bounding box not within raster image.\\n\")\n",
    "            sys.exit(1)\n",
    "    # Perform query after any bounding box trimming to allow sanity checking of\n",
    "    # size of resulting image\n",
    "    if query:\n",
    "        rainfall_data.query()\n",
    "\n",
    "    if extract:\n",
    "        #sys.stderr.write(\n",
    "        #    \"Extracting NIMROD raster to ASC file...\\n\")\n",
    "        # if file_out is None:\n",
    "        #    file_out = str(file_in) + \".asc\"\n",
    "        #sys.stderr.write(\n",
    "        #    \"  Outputting data array (%d rows x %d cols = %d pixels)\\n\"\n",
    "        #    % (rainfall_data.nrows, rainfall_data.ncols,\n",
    "        #       rainfall_data.nrows * rainfall_data.ncols))\n",
    "        rainfall_data.extract_asc(open(file_out, 'w'))\n",
    "    return rainfall_data\n",
    "\n",
    "################################### MY HELPER FUNCTIONS ######################################\n",
    "\n",
    "# Function to get file names for input\n",
    "def get_filenames(date_start, date_end, format='%Y-%m-%d %H:%M:%S'):\n",
    "    \n",
    "    # Get start and end dates\n",
    "    start = pd.to_datetime(date_start, format=format)\n",
    "    end = pd.to_datetime(date_end, format=format)\n",
    "\n",
    "    # Get timestamp for files\n",
    "    dates = pd.date_range(start=start, end=end)\n",
    "    years = dates.year\n",
    "    # Get file names\n",
    "    file_names = []\n",
    "    for date in dates:\n",
    "        datestring = str(date)[0:-9].replace('-', '')\n",
    "        name_string = 'metoffice-c-band-rain-radar_uk_' + datestring + '_1km-composite.dat.gz.tar'\n",
    "        file_names.append(name_string)\n",
    "    \n",
    "    return file_names, years\n",
    "    \n",
    "# Function to extract data\n",
    "def extract(file_from, bbox):\n",
    "    \n",
    "    tar_files = [join(file_from, ff) for ff in os.listdir(file_from) if ff.endswith(\".tar\")]\n",
    "    \n",
    "    if len(tar_files) > 0:\n",
    "        \n",
    "        dates = []\n",
    "        arrs = []\n",
    "\n",
    "        for tf in tar_files:\n",
    "\n",
    "            with tarfile.open(tf) as tar:\n",
    "                tar.extractall(file_from)\n",
    "\n",
    "                gz_files = [join(file_from, ff) for ff in os.listdir(file_from) if ff.endswith(\".gz\")]\n",
    "\n",
    "                for g in gz_files:\n",
    "\n",
    "                    with gzip.open(g, 'rb') as f_in:\n",
    "                        with open(join(file_from, os.path.splitext(g)[0]), 'wb') as f_out:\n",
    "                            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "                dat_files = [ff for ff in os.listdir(file_from) if ff.endswith(\".dat\")]\n",
    "\n",
    "                for df in dat_files:\n",
    "\n",
    "                    try:\n",
    "                        nf = nimrod_file(join(file_from, df), \n",
    "                                    #join(file_to, df.split(\".\")[0] + \".asc\"), \n",
    "                                    bbox=bbox)#, \n",
    "                                    #extract=True)\n",
    "                            \n",
    "                        xs = pd.Series(np.linspace(nf.x_left, nf.x_right, nf.ncols))\n",
    "                        ys = pd.Series(np.linspace(nf.y_bottom, nf.y_top, nf.nrows))\n",
    "                        dates.append(pd.to_datetime(df.split(\"_\")[-2]))\n",
    "                        arrs.append(np.array(nf.data).reshape(nf.nrows, nf.ncols))\n",
    "\n",
    "                    except:\n",
    "                        print(\"Not worked for \", df)\n",
    "\n",
    "    return [dates, arrs, xs, ys]\n",
    "\n",
    "# Function to get data (note: shouldn't be ran for a long time - uses up a lot of storage in temp folder)\n",
    "def download(start_date, end_date, folder_path, bbox, delete=True):\n",
    "    \n",
    "    # If new directory doesn't exist make it\n",
    "    temp_dir = join(folder_path, \"temp\")\n",
    "    if not os.path.isdir(temp_dir):\n",
    "        os.mkdir(temp_dir)\n",
    "    \n",
    "    # Get file names to download \n",
    "    file_names, years = get_filenames(start_date, end_date)\n",
    "    \n",
    "    for year in list(set(years)):\n",
    "        file_dir = '/badc/ukmo-nimrod/data/composite/uk-1km/' + str(year) + '/'\n",
    "\n",
    "        # login to FTP\n",
    "        f = ftplib.FTP(\"ftp.ceda.ac.uk\", username, password)\n",
    "\n",
    "        # Directory of files to save\n",
    "        f.cwd(file_dir)\n",
    "\n",
    "        for file in np.array(file_names)[years == year]:\n",
    "            \n",
    "            try:\n",
    "                # Copies data from ftp server\n",
    "                f.retrbinary(\"RETR %s\" % file, open(join(temp_dir, file), \"wb\").write)\n",
    "            except:\n",
    "                print(file, \" did not work.\")\n",
    "                \n",
    "    # Extracts and clips data\n",
    "    dates, arrs, xs, ys = extract(temp_dir, bbox)\n",
    "    \n",
    "    # Save data (horrible way to save it)\n",
    "    pd.Series(dates).to_csv(join(folder_path, \"timestamp.csv\"), index=False)\n",
    "    np.save(join(folder_path, \"arrays.npy\"), np.array(arrs) / 32)\n",
    "    xs.to_csv(join(folder_path, \"coords_x.csv\"), index=False)\n",
    "    ys.to_csv(join(folder_path, \"coords_y.csv\"), index=False)\n",
    "    \n",
    "    if delete:\n",
    "        shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### PARAMETERS TO CHANGE ######################################\n",
    "\n",
    "# output folder to save files\n",
    "root_path = r\"C:\\Users\\Amy\\OneDrive - Newcastle University (1)\\Documents\\PYRAMID\\data\\realtime\"\n",
    "output_path = join(root_path, \"MET\")\n",
    "if not exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "outpath_15min = join(output_path, \"15min\")\n",
    "if not exists(outpath_15min):\n",
    "    os.mkdir(outpath_15min)\n",
    "    \n",
    "# CEDA username and password\n",
    "username = \"amyycb\" \n",
    "password = \"b3034858\" # this is my CEDA account details, not sure what to do about this\n",
    "\n",
    "# dates for files \n",
    "start_date = pd.to_datetime(\"2023-06-20\")\n",
    "end_date = pd.to_datetime(\"2023-06-30\")\n",
    "\n",
    "# Bounding box for data \n",
    "e_l, n_l, e_u, n_u = [355000, 534000, 440000, 609000]\n",
    "bbox = [e_l, e_u, n_l, n_u]\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "# download and clip files (not this will take a while)\n",
    "download(start_date, end_date, output_path, bbox, delete=True)\n",
    "\n",
    "# change temporal resolution of data\n",
    "timestamp_series = pd.to_datetime(pd.read_csv(join(output_path, \"timestamp.csv\"))[\"0\"])\n",
    "arrs = np.load(join(output_path, \"arrays.npy\"))\n",
    "\n",
    "# new data resolution in seconds\n",
    "delta_t = str(15*60) + \"s\"\n",
    "\n",
    "start_date = timestamp_series.min().round(delta_t)\n",
    "end_date = timestamp_series.max().round(delta_t)\n",
    "\n",
    "new_timestamp = pd.date_range(\n",
    "    pd.to_datetime(start_date),\n",
    "    pd.to_datetime(end_date) + pd.Timedelta(1, \"d\"),\n",
    "    freq=str(15 * 60) + \"s\", \n",
    "    tz=\"UTC\"\n",
    ")\n",
    "\n",
    "new_arrays = np.full((new_timestamp.shape[0], arrs.shape[1], arrs.shape[2]), np.nan)\n",
    "\n",
    "for i, t in enumerate(new_timestamp):\n",
    "\n",
    "    cond = (timestamp_series >= t) & (timestamp_series < t + pd.Timedelta(delta_t))\n",
    "    subset = arrs[cond]\n",
    "    if subset.shape[0] > 0:\n",
    "        new_arrays[i] = np.nanmean(subset, axis=0)\n",
    "\n",
    "xs = pd.read_csv(join(output_path, \"coords_x.csv\"))\n",
    "xs.to_csv(join(outpath_15min, \"coords_x.csv\"), index=False)\n",
    "\n",
    "ys = pd.read_csv(join(output_path, \"coords_y.csv\"))\n",
    "ys.to_csv(join(outpath_15min, \"coords_y.csv\"), index=False)\n",
    "\n",
    "pd.Series(new_timestamp).to_csv(join(outpath_15min, \"timestamp.csv\"), index=False)\n",
    "np.save(join(outpath_15min, \"arrays.npy\"), new_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286de179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea567bfa",
   "metadata": {},
   "source": [
    "# Reading in Environment Agency rain gauge data (15 min)\n",
    "\n",
    "### Notes\n",
    "- Intense QC code read in, not sure how easy that will be, I had to clone it off Github and change line 10 of code as got an error with a package, proabbly due to Python versions. Think the package needs updating on Github but not sure who is still in charge of maintaining it. Need ETCCDI data (available in example data for Intense QC)\n",
    "\n",
    "\n",
    "### What does the code do?\n",
    "\n",
    "1. Download the data\n",
    "    - Try historic API\n",
    "    - Try real-time API\n",
    "    - Save data\n",
    "    \n",
    "\n",
    "### Outputs format\n",
    "- `\\root` folder path \n",
    "    - `\\EA` folder path (15 minute rain gauge data)\n",
    "        - `<station-id>_<eastings>_<northings>.csv` - individual 15-minute gauge data for station `<station-id>`\n",
    "        - `\\15min` folder path (15 minute rain gauge data) with filled in timestamp\n",
    "            - `<station-id>_<eastings>_<northings>.csv` - individual 15-minute gauge data for station `<station-id>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cda4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevent packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from os.path import join, exists\n",
    "import os\n",
    "from datetime import datetime\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8da106",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Inputs to change\n",
    "start_date = \"2023-06-20\"\n",
    "end_date = \"2023-06-30\"\n",
    "\n",
    "out_path = r\"C:\\Users\\Amy\\OneDrive - Newcastle University (1)\\Documents\\PYRAMID\\data\\realtime\"\n",
    "\n",
    "# Bounding box for data \n",
    "e_l, n_l, e_u, n_u = [355000, 534000, 440000, 609000]\n",
    "bbox = [e_l, e_u, n_l, n_u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdff12b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "ea_outpath = join(out_path, \"EA\")\n",
    "if not exists(ea_outpath):\n",
    "    os.mkdir(ea_outpath)\n",
    "    \n",
    "ea_15min_outpath = join(ea_outpath, \"15min\")\n",
    "if not exists(ea_15min_outpath):\n",
    "    os.mkdir(ea_15min_outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9702d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "\n",
    "# Get list of rainfall stations\n",
    "root = \"http://environment.data.gov.uk/flood-monitoring\"\n",
    "response = requests.get(root + \"/id/stations?parameter=rainfall\")\n",
    "r = response.json()[\"items\"]\n",
    "df = pd.json_normalize(r)\n",
    "\n",
    "# Get stations in area\n",
    "extent_stations = df.loc[(df.northing > n_l) & (df.northing < n_u) & (df.easting > e_l) & (df.easting < e_u)]\n",
    "station_ids = extent_stations.stationReference.to_list()\n",
    "names = np.array(extent_stations.stationReference + \"_\" + extent_stations.easting.astype(int).astype(\n",
    "    str) + \"_\" + extent_stations.northing.astype(int).astype(str) + \".csv\")\n",
    "\n",
    "now = datetime.now()\n",
    "# use real-time API if possible (last 28 days)\n",
    "if now - pd.to_datetime(start_date) < pd.Timedelta(\"28d\"):\n",
    "    for i, station in enumerate(station_ids):\n",
    "        try:\n",
    "            path = \"http://environment.data.gov.uk/flood-monitoring/id/measures/{id}-rainfall-tipping_bucket_raingauge-t-15_min-mm/readings?parameter=rainfall&startdate={startDate}&enddate={endDate}\"\n",
    "            path = path.replace(\"{id}\", station)\n",
    "            path = path.replace(\"{startDate}\", start_date)\n",
    "            path = path.replace(\"{endDate}\", end_date)\n",
    "            path = path.replace(\"{startTime}\", start_date)\n",
    "\n",
    "            response = requests.get(path)\n",
    "            r = response.json()[\"items\"]\n",
    "            df = pd.json_normalize(r)\n",
    "            if len(df) > 0:\n",
    "                data = pd.Series(df.value.values, index=pd.to_datetime(df.dateTime))\n",
    "                data.to_csv(join(ea_outpath, names[i]))\n",
    "        except:\n",
    "            print(station, \"not worked.\")\n",
    "\n",
    "# if not use historical API (seems to only work for last year- not very historical)\n",
    "else:\n",
    "    dates = pd.date_range(start_date, end_date)\n",
    "    iids = np.array(extent_stations.measures.str[0].str[\"@id\"])\n",
    "\n",
    "    for date_ts in dates:\n",
    "        date = str(date_ts).split(\" \")[0]\n",
    "        path = \"http://environment.data.gov.uk/flood-monitoring/archive/readings-full-{date}.csv\"\n",
    "        path = path.replace(\"{date}\", str(date))\n",
    "        r = requests.get(path)\n",
    "        full_data = []\n",
    "        if r.status_code == 200:\n",
    "            df = pd.read_csv(io.StringIO(r.text), index_col=0, parse_dates=True)\n",
    "            full_data.append(df[[measure in iids for measure in df.measure]])\n",
    "    full_data = pd.concat(full_data).groupby(\"stationReference\")\n",
    "\n",
    "    for i, station in enumerate(station_ids):\n",
    "        try:\n",
    "            (full_data.get_group(station).value).to_csv(join(ea_outpath, names[i])) # check units? Is this mm or mm/h because if it is mm it needs multiplying by 4?\n",
    "        except:\n",
    "            print(station, \"not worked.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a10050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filled in data incase missing values (don't think there is but just in case)\n",
    "new_timestamp = pd.date_range(\n",
    "    pd.to_datetime(start_date),\n",
    "    pd.to_datetime(end_date) + pd.Timedelta(1, \"d\"),\n",
    "    freq=str(15 * 60) + \"s\", \n",
    "    tz=\"UTC\"\n",
    ")\n",
    "\n",
    "for f in os.listdir(ea_outpath):\n",
    "    if f.endswith(\".csv\"):\n",
    "        tab = pd.read_csv(join(ea_outpath, f), index_col=0)\n",
    "        tab.index = pd.to_datetime(tab.index)\n",
    "\n",
    "        filled_in = pd.Series(np.nan, index=new_timestamp)\n",
    "        filled_in.loc[tab.index] = tab.iloc[:, 0].values\n",
    "\n",
    "        filled_in.to_csv(join(ea_15min_outpath, f))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
